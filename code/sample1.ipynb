{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nibabel as nib\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from numpy import load, savez_compressed\n",
    "from natsort import natsorted\n",
    "\n",
    "from preprocess.get_subvolume import get_training_sub_volumes, get_test_subvolumes\n",
    "\n",
    "\n",
    "dataset_folder = \"/media/bersek/56DAFC88DAFC65A1/BRATS/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tf.__version__)\n",
    "tf.config.list_physical_devices(\"GPU\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_dirs(volumes_paths):\n",
    "    processed_paths = {}\n",
    "    processed_sample_paths = {}\n",
    "    SAMPLES_FOLDERS = volumes_paths\n",
    "    PARENT_DIR = os.getcwd()\n",
    "    ANTER = os.path.abspath(os.path.join(os.path.dirname(PARENT_DIR), '.'))\n",
    "    processed_paths[\"ANTER\"] = ANTER\n",
    "    DATABASE_DIR = os.path.join(ANTER, \"BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\")\n",
    "\n",
    "    processed_paths[\"PROCESSED_DIR\"] = os.path.join(ANTER, \"processed\")\n",
    "    PROCESSED_DIR = processed_paths[\"PROCESSED_DIR\"]\n",
    "\n",
    "    processed_paths[\"3D\"] = os.path.join(PROCESSED_DIR, \"3D\")\n",
    "    UNET_3D = processed_paths[\"3D\"]\n",
    "\n",
    "    processed_paths[\"SUBVOLUME_FOLDER\"] = os.path.join(UNET_3D,\"subvolumes\")\n",
    "    processed_paths[\"SUBVOLUME_MASK_FOLDER\"] = os.path.join(UNET_3D,\"subvolumes_masks\")\n",
    "    processed_paths[\"ROTATION_MATRIX\"] = os.path.join(UNET_3D,\"rotation_matrix\")\n",
    "    processed_paths[\"RESULTS_3D\"] = os.path.join(UNET_3D,\"subvolumes_predict\")\n",
    "\n",
    "    for path in processed_paths:\n",
    "        dir_exists = os.path.exists(processed_paths[path])\n",
    "        if not dir_exists:\n",
    "            os.makedirs(processed_paths[path])\n",
    "\n",
    "    processed_paths.pop(\"PROCESSED_DIR\")\n",
    "    processed_paths.pop(\"ANTER\")\n",
    "    processed_paths.pop(\"3D\")\n",
    "    for path in processed_paths:\n",
    "        if path == \"RESULTS_3D\":\n",
    "            train_files, val_files = train_test_split(SAMPLES_FOLDERS, test_size=0.2, random_state=42)\n",
    "            test_files, val_files = train_test_split(val_files, test_size=0.5, random_state=42)\n",
    "            SAMPLES_FOLDERS_TEST_TRAIN = test_files\n",
    "            TEST_SAMPLES = SAMPLES_FOLDERS_TEST_TRAIN\n",
    "        else:\n",
    "            SAMPLES_FOLDERS_TEST_TRAIN = SAMPLES_FOLDERS\n",
    "\n",
    "        for sample in SAMPLES_FOLDERS_TEST_TRAIN:\n",
    "            sample_dir = os.path.join(processed_paths[path], sample)\n",
    "            dir_exists = os.path.exists(sample_dir)\n",
    "            if not dir_exists:\n",
    "                os.makedirs(sample_dir)\n",
    "        processed_sample_paths[path] = processed_paths[path]\n",
    "    processed_sample_paths[\"DATABASE_DIR\"] = DATABASE_DIR\n",
    "    processed_sample_paths[\"SAMPLES\"] = SAMPLES_FOLDERS\n",
    "    processed_sample_paths[\"TEST_SAMPLES\"] = TEST_SAMPLES\n",
    "    return processed_sample_paths, train_files, val_files, test_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_volumes(volumes_path):\n",
    "    volumes = [name for name in os.listdir(volumes_path) if name.startswith(\"BraTS20\")]\n",
    "    num_volumes = int(len(volumes))\n",
    "    print(volumes[0])\n",
    "    return volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_file_name(sample, mask=1):\n",
    "    \"\"\"Funcion que genera el nombre de los archivos para automatizar la lectura\n",
    "\n",
    "    :param sample: codigo del paciente (carpeta)\n",
    "    :type sample: string\n",
    "    :param mask: Define si se quiere la mascara o el volumen normal, defaults to False\n",
    "    :type mask: bool, optional\n",
    "    :return: nombre del archivo a leer\n",
    "    :rtype: path\n",
    "    \"\"\"\n",
    "    if mask==1:\n",
    "        file_name = sample+\"_seg.nii\"\n",
    "    elif mask==2:\n",
    "        file_name = sample+\"_t1.nii\"\n",
    "    \n",
    "    elif mask==3:\n",
    "        file_name = sample+\"_flair.nii\"\n",
    "    elif mask==4:\n",
    "        file_name = sample+\"_t1ce.nii\"\n",
    "    elif mask==5:\n",
    "        file_name = sample+\"_t2.nii\"\n",
    "    file_name = os.path.join(sample, file_name)\n",
    "    return file_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_volumes_train(sample):\n",
    "    \"\"\"Esta funcion recibe el nombre de una muestra (carpeta) y genera los sub-volumenes.\n",
    "    SOLO PARA TRAIN!!\n",
    "\n",
    "    :param sample: nombre de la carpeta que contiene el volumen y su mascara\n",
    "    :type sample: path\n",
    "    \"\"\"\n",
    "    img = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 1))\n",
    "    img_mask = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 2))\n",
    "    img = nib.load(img)\n",
    "    img_mask = nib.load(img_mask)\n",
    "    image = img.get_fdata()\n",
    "    image_mask = img_mask.get_fdata()\n",
    "    SAVE_PATH_SUBVOLUME = os.path.join(paths[\"SUBVOLUME_FOLDER\"], sample)\n",
    "    SAVE_PATH_SUBMASK = os.path.join(paths[\"SUBVOLUME_MASK_FOLDER\"], sample)\n",
    "    ROTATION_MATRIX_PATH = os.path.join(paths[\"ROTATION_MATRIX\"], sample,sample)\n",
    "    get_training_sub_volumes(image, img.affine, image_mask, img_mask.affine, \n",
    "                                    SAVE_PATH_SUBVOLUME, SAVE_PATH_SUBMASK, ROTATION_MATRIX_PATH,\n",
    "                                    classes=1, \n",
    "                                    orig_x = orig_x, orig_y = orig_y, orig_z = orig_z, \n",
    "                                    output_x = output_x, output_y = output_y, output_z = output_z,\n",
    "                                    stride_x = stride_x, stride_y = stride_y, stride_z = stride_z,\n",
    "                                    background_threshold=back_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sub_volumes_test(sample):\n",
    "    \"\"\"Esta funcion recibe el nombre de una muestra (carpeta) y genera los sub-volumenes.\n",
    "    SOLO PARA TEST!!\n",
    "\n",
    "    NOTA: el stride de los volumenes de test es mas grande \n",
    "    debido a que genera muchas mas imagenes y no tengo espacio.\n",
    "\n",
    "    :param sample: nombre de la carpeta que contiene el volumen y su mascara\n",
    "    :type sample: path\n",
    "    \"\"\"\n",
    "    img = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 1))\n",
    "    img_mask = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 2))\n",
    "    img = nib.load(img)\n",
    "    img_mask = nib.load(img_mask)\n",
    "    image = img.get_fdata()\n",
    "    image_mask = img_mask.get_fdata()\n",
    "    SAVE_PATH_SUBVOLUME = os.path.join(paths[\"SUBVOLUME_FOLDER\"], sample)\n",
    "    SAVE_PATH_SUBMASK = os.path.join(paths[\"SUBVOLUME_MASK_FOLDER\"], sample)\n",
    "    ROTATION_MATRIX_PATH = os.path.join(paths[\"ROTATION_MATRIX\"], sample,sample)\n",
    "    get_test_subvolumes(image, img.affine, image_mask, img_mask.affine, \n",
    "                                    SAVE_PATH_SUBVOLUME, SAVE_PATH_SUBMASK, ROTATION_MATRIX_PATH,\n",
    "                                    orig_x = orig_x, orig_y = orig_y, orig_z = orig_z, \n",
    "                                    output_x = output_x, output_y = output_y, output_z = output_z,\n",
    "                                    stride_x = stride_x, stride_y = stride_y, stride_z = stride_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"content/data/volume_1_slice_0.h5\"\n",
    "\"/media/bersek/56DAFC88DAFC65A1/BRATS/BraTS2020_TrainingData/MICCAI_BraTS2020_TrainingData\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "volumes_folders = count_volumes(dataset_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, train_files, val_files, test_files = make_dirs(volumes_folders)\n",
    "test_files.extend(val_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(paths[\"SUBVOLUME_MASK_FOLDER\"],path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(paths[\"DATABASE_DIR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_sub_volumes_train(train_files[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import load\n",
    "from numpy import savez_compressed\n",
    "import nibabel as nib\n",
    "file = os.path.join(paths[\"SUBVOLUME_MASK_FOLDER\"],\"BraTS20_Training_355\",\"submask41.npz\")\n",
    "#file = os.path.join(paths[\"SUBVOLUME_FOLDER\"],\"BraTS20_Training_355\",\"subvolume40.npz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths[\"SAMPLES\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in test_files:\n",
    "    print(path)\n",
    "    for i in range (45):\n",
    "        file = os.path.join(paths[\"RESULTS_3D\"],path,\"subvolume{}.npz\".format(i+1))\n",
    "        dict_data_file = load(file)['arr_0']\n",
    "        forma = dict_data_file.shape\n",
    "        for x in range(forma[0]):\n",
    "            for y in range(forma[1]):\n",
    "                for z in range(forma[2]):\n",
    "                    if dict_data_file[x,y,z] != 0.0:\n",
    "                        print(dict_data_file[x,y,z])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data_file = load(file)['arr_0']\n",
    "dict_data_file.max()\n",
    "dict_data_file.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_data_file.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximo = 4.0\n",
    "minimo = 0.0\n",
    "contador = 0\n",
    "contador1 = 0\n",
    "for i in range (45):\n",
    "    file = os.path.join(paths[\"RESULTS_3D\"],\"BraTS20_Training_017\",\"subvolume{}.npz\".format(i+1))\n",
    "    dict_data_file = load(file)['arr_0']\n",
    "    for x in dict_data_file:\n",
    "        for y in x:\n",
    "            for z in y:\n",
    "                if z!=0.0 :\n",
    "                    #print(z,file)\n",
    "                    contador += 1\n",
    "                    contador1 += 1\n",
    "    if contador1/(80*80*32) !=0.0:\n",
    "        print(contador1)\n",
    "        print(contador1/(80*80*32))\n",
    "    contador1 = 0\n",
    "#print(maximo,data_file)\n",
    "contador/(45*80*80*32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = \"BraTS20_Training_345\"\n",
    "img = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 4))\n",
    "img_mask = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 1))\n",
    "img = nib.load(img)\n",
    "img_mask = nib.load(img_mask)\n",
    "image = img.get_fdata()\n",
    "image_mask = img_mask.get_fdata()\n",
    "print(sample)\n",
    "img_affine = img_mask.affine\n",
    "contador = 0\n",
    "contador1 = 0\n",
    "\n",
    "forma = image_mask.shape\n",
    "for x in range(forma[0]):\n",
    "    for y in range(forma[1]):\n",
    "        for z in range(forma[2]):\n",
    "            if image_mask[x,y,z] == 4.0 or image_mask[x,y,z] == 1.0 or image_mask[x,y,z] == 2.0 :\n",
    "                contador += 1\n",
    "                \n",
    "contador/(240*240*155)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"/media/bersek/56DAFC88DAFC65A1/BRATS/A00028185\"\n",
    "maximo = 0.0\n",
    "for i in range (191):\n",
    "    file = os.path.join(\"/media/bersek/56DAFC88DAFC65A1/BRATS/A00028185\",\"submask{}.npz\".format(i+1))\n",
    "    dict_data_file = load(file)['arr_0']\n",
    "    if dict_data_file.max() > maximo:\n",
    "        maximo = dict_data_file.max()\n",
    "        data_file = file\n",
    "print(maximo,data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_x = 240\n",
    "orig_y = 240\n",
    "orig_z = 155 \n",
    "\n",
    "output_x = 80\n",
    "output_y = 80\n",
    "output_z = 32\n",
    "\n",
    "stride_x = 80\n",
    "stride_y = 80\n",
    "stride_z = 31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contador = 0\n",
    "for i_2 in range(0, orig_z-output_z+2, stride_z):#(0, orig_x-output_x+1, output_x-1):\n",
    "    if i_2 < 124:\n",
    "        i = i_2\n",
    "    else:\n",
    "        print(orig_z-output_z+2)\n",
    "        i = i_2-1\n",
    "    for j in range(0, orig_y-output_y+1, stride_y):\n",
    "        for k in range(0, orig_x-output_x+1, stride_x):\n",
    "            print(\"X: \", k, \"Y: \", j, \"Z: \", i)\n",
    "            contador += 1 \n",
    "\n",
    "print(contador)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample in test_files[:5]:\n",
    "    img = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 4))\n",
    "    img_mask = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 1))\n",
    "    img = nib.load(img)\n",
    "    img_mask = nib.load(img_mask)\n",
    "    image = img.get_fdata()\n",
    "    image_mask = img_mask.get_fdata()\n",
    "    print(sample)\n",
    "    img_affine = img_mask.affine\n",
    "    SAVE_PATH_SUBVOLUME = os.path.join(paths[\"SUBVOLUME_FOLDER\"], sample)\n",
    "    SAVE_PATH_SUBMASK = os.path.join(paths[\"SUBVOLUME_MASK_FOLDER\"], sample)\n",
    "    ROTATION_MATRIX_PATH = os.path.join(paths[\"ROTATION_MATRIX\"], sample,sample)\n",
    "\n",
    "    forma = image_mask.shape\n",
    "    for x in range(forma[0]):\n",
    "        for y in range(forma[1]):\n",
    "            for z in range(forma[2]):\n",
    "                if image_mask[x,y,z] == 4.0 or image_mask[x,y,z] == 1.0:\n",
    "                    image_mask[x,y,z] = 1.0\n",
    "                else:\n",
    "                    image_mask[x,y,z] = 0.0\n",
    "    savez_compressed(os.path.join(sample), image.astype(np.float32))\n",
    "    savez_compressed(os.path.join(sample+\"_mask\"), image_mask.astype(np.float32))\n",
    "    nii_segmented = nib.Nifti1Image(image_mask.astype(np.float32), img_affine.astype(np.float32))\n",
    "    nib.save(nii_segmented, os.path.join(sample+\".nii\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "sample = test_files[20]\n",
    "print(sample)\n",
    "img = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 4))\n",
    "img_mask = os.path.join(paths[\"DATABASE_DIR\"], create_file_name(sample, 1))\n",
    "img = nib.load(img)\n",
    "img_mask = nib.load(\"/media/bersek/56DAFC88DAFC65A1/BRATS/code/BraTS20_Training_045_seg.nii\")\n",
    "image = img.get_fdata()\n",
    "image = image[::-1]\n",
    "image_mask = img_mask.get_fdata()\n",
    "image_mask = image_mask[::-1]\n",
    "\n",
    "z = 105\n",
    "y = 150\n",
    "x = 140\n",
    "threshold = 0.1\n",
    "n1 =50\n",
    "m1 = 240-(64-n1)\n",
    "\n",
    "n2 =50\n",
    "m2 = 240-(64-n2)\n",
    "\n",
    "n3 =50\n",
    "m3 = 240-(65-n3)\n",
    "\n",
    "color1 = \"magma\"\n",
    "color2 = \"cool\"\n",
    "threshold = 0.1\n",
    "image_mask[:,:,:][image_mask[:,:,:]< threshold] = np.nan\n",
    "\n",
    "plt.figure(plt.figure(figsize=(12, 8)))\n",
    "plt.subplots_adjust(left=0.1,\n",
    "                    bottom=0.1, \n",
    "                    right=0.9, \n",
    "                    top=0.9, \n",
    "                    wspace=0.1, \n",
    "                    hspace=0.6)\n",
    "plt.subplot(1,3,1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Original\")\n",
    "plt.imshow(np.transpose(image[x,:,:],(1,0))[::-1], 'gray', interpolation='none')\n",
    "#plt.imshow(np.transpose(image_mask[x,:,:],(1,0))[::-1], color2, interpolation='none', alpha=0.3)\n",
    "plt.subplot(1,3,2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Segementacion Manual\")\n",
    "plt.imshow(np.transpose(image[x,:,:],(1,0))[::-1], 'gray', interpolation='none')\n",
    "plt.imshow(np.transpose(image_mask[x,:,:],(1,0))[::-1], color1, interpolation='none', alpha=0.4)\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Segementacion Automatica\")\n",
    "plt.imshow(np.transpose(image[x,:,:],(1,0))[::-1], 'gray', interpolation='none')\n",
    "plt.imshow(np.transpose(image_mask[x,:,:],(1,0))[::-1], color1, interpolation='none', alpha=0.4)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(\"test_{}.png\".format(color1), dpi=1200, \n",
    "                transparent=True, \n",
    "                bbox_inches='tight')\n",
    "\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image[x,:,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_mask[:,45:200,z].shape"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "025d0611cc4da457942597668eb92d0e0ea6adb3492e08c6baf3cabfed307b11"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('tumores': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
